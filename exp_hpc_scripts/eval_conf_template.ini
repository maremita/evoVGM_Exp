# nb3_l5k_datajc69_evojc69.ini

[io]
# Used to save training data, scores and figures
output_path = nb_sequences
# If False the program run the evaluation and save resutls in output_path
# else the program load results directly from the file (if it exists)
scores_from_file = True

[data]
# Get data from FASTA files or evolve new sequences
from_fasta = True
alignment_size = 5000
# Branch lengths is list of M floats separated by comma (w/out space)
# M is the number of sequences to be evolved
branch_lengths = 0.1,0.3,0.45
# Substitution rates
#        AG    AC    AT    GC    GT    CT
rates = 0.16, 0.16, 0.16, 0.16, 0.16, 0.16
#rates = 0.16
# Relative frequencies
#        A     C      G    T
freqs = 0.25, 0.25, 0.25, 0.25
# freqs = 0.25

[subvmodel]
# jc69 := EvoVGM_JC69: infer a and b latent variables
# k80  := EvoVGM_K80 : infer a, b, k latent variables
# gtr  := EvoVGM_GTR : infer a, b, r, f latent variables
evomodel = jc69

[hperparams]
nb_replicates = 10
alpha_kl = 0.0001
nb_samples = 100
hidden_size = 32
nb_layers = 3
sample_temp = 0.1
n_epochs = 5000
# optimizer type : adam | sgd
optim=adam
learning_rate = 0.005
optim_weight_decay = 0.00001

[priors]
# accepted values for catgorical variables:  uniform | 0.2,0.4,0.2,0.2
# To implement empirical
ancestor_prior = uniform
rates_prior = uniform
freqs_prior = uniform
# accepted values for branch prior: 2 float values separated by comma (w/out space)
# mu and sigma for Lognormal (mean = exp(mu - ((sigma^2) / 2))
# alpha and beta (rate) for Gamma (mean = alpha/beta)
branch_prior = 0.1,1.
kappa_prior = 1.,1.

[settings]
job_name = nb3_l5k_datajc69_evojc69
# cpu | cuda | cuda:0
device=cpu
seed=14
verbose=True

[plotting]
# To render Tex text in plots, Matplotlib requires
# Latex, dvipng, Ghostscript and type1ec.sty found in cm-super
# If Latex and other required packages are not installed, put to False
plt_usetex=False
y_limits = -4,0
print_xtick_every = 500
